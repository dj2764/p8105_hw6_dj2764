---
title: "p8105_hw6_dj2764"
author: "Daniel Jiao (dj2764)"
output: github_document
---

```{r message = FALSE, warning = FALSE}
library(tidyverse)
library(modelr)
library(broom)
```

# Problem 1
## Load & clean the data
```{r message = FALSE, warning = FALSE}
homicide_raw <- read_csv("data/homicide-data.csv")

homicide_df <- homicide_raw |> 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_race = str_to_lower(victim_race),
    victim_sex  = str_to_lower(victim_sex),
    victim_age  = as.numeric(victim_age),
    solved = if_else(disposition == "Closed by arrest", 1, 0)
  ) |> 
  # remove cities
  filter(
    !(city_state %in% c(
      "Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"
    ))
  ) |> 
  # keep white/black
  filter(victim_race %in% c("white", "black")) |> 
  drop_na(victim_age, victim_sex, victim_race)

homicide_df |> select(city_state, solved, victim_race, victim_age)
```

## Baltimore, MD logistic regression
```{r}
baltimore_df <- homicide_df |> 
  filter(city_state == "Baltimore, MD")

baltimore_fit <- glm(
  solved ~ victim_age + victim_sex + victim_race,
  data = baltimore_df,
  family = binomial()
)

baltimore_tidy <- broom::tidy(baltimore_fit, conf.int = TRUE, exponentiate = TRUE)

baltimore_OR_male_vs_female <- baltimore_tidy |> 
  filter(term == "victim_sexmale") |> 
  select(term, estimate, conf.low, conf.high)

baltimore_OR_male_vs_female
```

## Fit logistic regressions for all cities
```{r warning = FALSE}
city_results <- homicide_df |> 
  nest(data = -city_state) |> 
  mutate(
    model = map(data, ~ glm(
      solved ~ victim_age + victim_sex + victim_race,
      data = .x,
      family = binomial()
    )),
    tidied = map(model, ~ broom::tidy(.x, conf.int = TRUE, exponentiate = TRUE))
  ) |> 
  unnest(tidied) |> 
  filter(term == "victim_sexmale") |> 
  select(city_state, estimate, conf.low, conf.high)
```


## Plot odds ratios + confidence intervals
```{r}
city_results_plot <- city_results |> 
  arrange(estimate) |> 
  mutate(city_state = factor(city_state, levels = city_state))

ggplot(city_results_plot, aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.1) +
  geom_hline(yintercept = 1, linetype = "dashed") +
  coord_flip() +
  labs(
    title = "Adjusted OR (Male vs Female Victims) for Homicide Being Solved",
    x = "City",
    y = "Adjusted Odds Ratio (logistic regression)"
  )
```

Interpretation of the adjusted odds ratio plot

The plot displays the adjusted odds ratios (ORs) and 95% confidence intervals comparing the odds of a homicide being solved for male victims relative to female victims, after controlling for victim age and race. The cities are ordered by their estimated ORs from lowest to highest.

Across most cities, the estimated OR is below 1, indicating that homicides involving male victims are generally less likely to be solved compared with those involving female victims, holding age and race constant. This pattern is consistent with national investigative trends and suggests that cases involving female victims may receive more investigative attention or may be easier to resolve.

Several cities show OR estimates far below 1 (e.g., New York, NY; Baton Rouge, LA), with relatively narrow confidence intervals, suggesting a robust and substantial difference in solve rates by victim sex. In contrast, a smaller number of cities exhibit ORs close to or slightly above 1, indicating little or no difference in solve probability between male and female victims.

The width of the confidence intervals varies substantially across cities. Cities with larger intervals likely have smaller sample sizes or less variability in solve rates across sexes, leading to less precise estimates. A few cities (e.g., Albuquerque, NM; Stockton, CA) display very wide confidence intervals, sometimes crossing 1, reflecting instability in the logistic regression estimates and possibly complete or near-complete separation in the data.

Overall, the plot highlights a consistent trend across U.S. cities: male homicide victims tend to have lower adjusted odds of having their cases solved, though the magnitude and certainty of this effect vary considerably by city.




# Problem 2
## Load and prepare data
```{r}
library(p8105.datasets)
data("weather_df")

weather_small <- weather_df |> 
  select(tmax, tmin, prcp) |> 
  drop_na()

fit = lm(tmax ~ tmin + prcp, data = weather_small)
```

## Run 5000 bootstrap replications
```{r}
set.seed(123)

boot_results <- tibble(
  boot_id = 1:5000
) |> 
  mutate(
    sample = map(
      boot_id,
      ~ sample_n(weather_small, size = nrow(weather_small), replace = TRUE)
    ),
    
    model = map(sample, ~ lm(tmax ~ tmin + prcp, data = .x)),
    
    r2 = map_dbl(model, ~ glance(.x)$r.squared),
    
    beta_ratio = map_dbl(
      model,
      ~ {
        coefs <- tidy(.x)
        beta1 <- coefs$estimate[coefs$term == "tmin"]
        beta2 <- coefs$estimate[coefs$term == "prcp"]
        beta1 / beta2
      }
    )
  )
```

## Plot RÂ² distribution
```{r}
ggplot(boot_results, aes(x = r2)) +
  geom_histogram(bins = 50, color = "white") +
  labs(
    title = "Bootstrap Distribution of RÂ²",
    x = "RÂ²",
    y = "Frequency"
  )
```

The bootstrap distribution of R^2 is approximately symmetric and bell-shaped, centered around roughly 0.94. The spread of the distribution is quite narrow, with almost all estimates falling between 0.935 and 0.947. This indicates that the linear model with tmax as the response and tmin and prcp as predictors explains a stable and consistent proportion of the variance across bootstrap resamples. The small amount of variability suggests that the modelâ€™s explanatory power is not highly sensitive to sampling fluctuations in the original dataset.
 
## Plot Î²Â¹ / Î²Â² distribution
```{r}
ggplot(boot_results, aes(x = beta_ratio)) +
  geom_histogram(bins = 50, color = "white") +
  labs(
    title = "Bootstrap Distribution of Î²Â¹ / Î²Â²",
    x = "Î²Â¹ / Î²Â² (tmin coefficient / prcp coefficient)",
    y = "Frequency"
  )

```

In contrast, the bootstrap distribution of the ratio ð›½1/ð›½2 (coefficient of tmin divided by coefficient of prcp) is asymmetric and strongly right-skewed, with a long tail extending toward very negative values. The bulk of the estimates fall between roughly âˆ’250 and âˆ’150 , but the presence of extreme outliers indicates instability in this ratio. This behavior is expected because the denominator (prcp coefficient) is often close to zero; even small changes in this coefficient can cause the ratio to vary dramatically, amplifying noise and producing highly variable estimates.

Overall,R^2 exhibits a tight, well-behaved bootstrap distribution, whereas ð›½1/ð›½2 shows high sensitivity and instability, reflecting the difficulty of interpreting a ratio involving a coefficient that is close to zero.

## Compute 95% confidence intervals
```{r}
r2_ci <- boot_results |> 
  summarize(
    lower = quantile(r2, 0.025),
    upper = quantile(r2, 0.975)
  )

beta_ratio_ci <- boot_results |> 
  summarize(
    lower = quantile(beta_ratio, 0.025),
    upper = quantile(beta_ratio, 0.975)
  )

r2_ci
beta_ratio_ci
```

# Problem 3
## Load and clean the data
```{r message = FALSE}
birthweight <- read_csv("data/birthweight.csv")

birthweight_df <- birthweight |>
  # make some categorical variables factors with labels
  mutate(
    babysex = factor(babysex, levels = c(1, 2),
                     labels = c("male", "female")),
    frace = factor(frace,
                   levels = c(1, 2, 3, 4, 8, 9),
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    mrace = factor(mrace,
                   levels = c(1, 2, 3, 4, 8),
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    malform = factor(malform, levels = c(0, 1),
                     labels = c("absent", "present"))
  ) |>
  # drop rows with any missing relevant variables (this dataset typically has no NAs, but check)
  drop_na()

# quick check for NAs (should all be zero)
birthweight_df |>
  summarise(across(everything(), \(x) sum(is.na(x))))
```

## Propose a regression model for birthweight
```{r}
bw_mod <- lm(
  bwt ~ babysex + bhead + blength + gaweeks +
    ppbmi + ppwt + wtgain + momage + mrace + smoken,
  data = birthweight_df
)

summary(bw_mod)
```

To model birthweight, I began by considering biologically and clinically plausible predictors that are known to influence fetal growth. Birthweight is strongly determined by fetal size at birth, gestational maturity, maternal physical characteristics, and prenatal behaviors. Based on this reasoning, I included:

Fetal size indicators: head circumference (bhead) and length (blength)

Gestational maturity: weeks of gestation (gaweeks)

Maternal anthropometrics: pre-pregnancy BMI (ppbmi), pre-pregnancy weight (ppwt), and pregnancy weight gain (wtgain)

Maternal demographic factors: race (mrace) and age (momage)

Behavioral exposures: smoking during pregnancy (smoken)

Infant sex: (babysex), as male infants tend to weigh more on average

These variables reflect a domain-informed model, rather than a purely data-driven variable selection procedure. The goal was to include predictors with well-established relationships to birthweight while avoiding unnecessary interactions or higher-order terms that would complicate interpretation.

## Residuals vs fitted plot (using add_predictions / add_residuals)
```{r}
bw_aug <- birthweight_df |>
  modelr::add_predictions(bw_mod) |>
  modelr::add_residuals(bw_mod)

ggplot(bw_aug, aes(x = pred, y = resid)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "Residuals vs Fitted Values for Birthweight Model",
    x = "Predicted birthweight (grams)",
    y = "Residuals"
  )

```

The residuals vs fitted values plot shows that the residuals are centered around zero across the full range of predicted birthweights, indicating that the model does not exhibit strong systematic bias. There is no clear curvature or pattern in the residual cloud, which suggests that the assumed linear relationship between the predictors and birthweight is appropriate.

The spread of residuals remains relatively constant for fitted values between roughly 2500 and 4000 grams, where most observations fall. At very low fitted birthweights (under ~1500 grams), residual variability increases and a few extreme outliers appear. This pattern is expected because extremely small infants are comparatively rare and tend to have more heterogeneous birth outcomes. These points do not represent a violation of model assumptions but rather reflect natural variability in this part of the data.

Overall, the plot does not indicate major issues with nonlinearity or heteroscedasticity, and the linear regression model appears to provide a reasonable fit for the majority of observations.

## Model A: length at birth + gestational age (main effects only)
```{r}
bw_mod_A <- lm(
  bwt ~ blength + gaweeks,
  data = birthweight_df
)

```

## Model B: head circumference, length, sex, and all interactions (including three-way)
```{r}
bw_mod_B <- lm(
  bwt ~ bhead * blength * babysex,
  data = birthweight_df
)

```

## Cross-validated prediction error with crossv_mc
```{r}
set.seed(123)

cv_df <- modelr::crossv_mc(birthweight_df, n = 100) |>
  mutate(
    train = map(train, as_tibble),
    test  = map(test, as_tibble)
  ) |>
  mutate(
    mod_main = map(train, ~ lm(
      bwt ~ babysex + bhead + blength + gaweeks +
        ppbmi + ppwt + wtgain + momage + mrace + smoken,
      data = .x
    )),
    mod_A = map(train, ~ lm(
      bwt ~ blength + gaweeks,
      data = .x
    )),
    mod_B = map(train, ~ lm(
      bwt ~ bhead * blength * babysex,
      data = .x
    ))
  ) |>
  mutate(
    rmse_main = map2_dbl(mod_main, test, ~ modelr::rmse(.x, .y)),
    rmse_A    = map2_dbl(mod_A,    test, ~ modelr::rmse(.x, .y)),
    rmse_B    = map2_dbl(mod_B,    test, ~ modelr::rmse(.x, .y))
  )

```

## summarize / plot
```{r}
rmse_long <- cv_df |>
  select(rmse_main, rmse_A, rmse_B) |>
  pivot_longer(
    cols = everything(),
    names_to = "model",
    values_to = "rmse"
  ) |>
  mutate(
    model = recode(
      model,
      rmse_main = "Proposed model",
      rmse_A    = "Length + gestational age",
      rmse_B    = "Head Ã— length Ã— sex (full interaction)"
    )
  )

# boxplot of RMSE distributions
ggplot(rmse_long, aes(x = model, y = rmse)) +
  geom_boxplot() +
  labs(
    title = "Cross-validated RMSE by model",
    x = "Model",
    y = "RMSE (test set)"
  ) +
  theme(axis.text.x = element_text(angle = 20, hjust = 1))

# numeric summary
rmse_long |>
  group_by(model) |>
  summarise(
    mean_rmse = mean(rmse),
    median_rmse = median(rmse)
  )

```




















